{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "import xml.etree.ElementTree as ET\n",
    "import argparse\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = []\n",
    "total_img = 0\n",
    "list_file_per_classes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_txt = open('D:/Pemrograman/Python/Project/Hidup-Sehat-Machine-Learning/ObjectDetection/workspace/annotations/labels.txt','r')\n",
    "for x in classes_txt:\n",
    "    # print(x.strip())\n",
    "    list_file_per_classes[x.strip()]=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = r\"D:\\Pemrograman\\Python\\Project\\google_image_scraper\\Google-Image-Scraper\\datasets\\food\\test\"\n",
    "# path_2 = r\"D:\\Pemrograman\\Python\\Project\\google_image_scraper\\Google-Image-Scraper\\photos\\nasi kotak indonesia\"\n",
    "# path_3 = r\"D:\\Pemrograman\\Python\\Project\\google_image_scraper\\Google-Image-Scraper\\photos\\makan nasi pake tempe\"\n",
    "# os.chdir(path)\n",
    "for xml_file in glob.glob(path_1 + '/*.xml'):\n",
    "    total_img +=1\n",
    "    file_names = xml_file.split('\\\\')[1]\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    filename = root.find('filename').text\n",
    "    already_list = []\n",
    "    for member in root.findall('object'):\n",
    "        kelas = member.find('name').text.strip()\n",
    "        # if kelas == 'Telur Dadar':\n",
    "            # print(filename)\n",
    "        if kelas not in already_list:\n",
    "            already_list.append(kelas)\n",
    "            list_file_per_classes[kelas] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ayam': 28,\n",
       " 'Tahu Goreng': 4,\n",
       " 'Tomat': 12,\n",
       " 'Donat Dilapisi Gula': 18,\n",
       " 'Donat Dilapisi Coklat': 14,\n",
       " 'Strawberry Frosted Donut (Dunkin Donuts)': 18,\n",
       " 'Chocolate Frosted Donut (Dunkin Donuts)': 15,\n",
       " 'Mentimun': 13,\n",
       " 'Telur Dadar': 2,\n",
       " 'Nasi Putih': 38,\n",
       " 'Tempe Goreng': 23,\n",
       " 'Telur Asin': 7,\n",
       " 'Telur Balado': 9,\n",
       " 'Telur Ceplok': 13,\n",
       " 'Mie': 10,\n",
       " 'Roti': 1,\n",
       " 'Es Krim': 25,\n",
       " 'Es Loli': 25,\n",
       " 'Roti Bagel': 25,\n",
       " 'Pretzel Cinnamon Sugar': 25,\n",
       " 'Cheeseburger': 25,\n",
       " 'Hotdog': 25,\n",
       " 'Kentang Tumbuk': 25,\n",
       " 'Kubis': 25,\n",
       " 'Brokoli': 25,\n",
       " 'Kembang Kol': 25,\n",
       " 'Paprika Merah': 25,\n",
       " 'Stroberi': 25,\n",
       " 'Jeruk': 25,\n",
       " 'Lemon': 25,\n",
       " 'Nanas': 25,\n",
       " 'Pisang': 25,\n",
       " 'Nangka': 25,\n",
       " 'Spaghetti Carbonara': 25,\n",
       " 'Pizza dengan Daging dan Sayuran': 25,\n",
       " 'Jagung': 25}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_file_per_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# import io\n",
    "# import xml.etree.ElementTree as ET\n",
    "# import argparse\n",
    "\n",
    "# path = \"D:/Pemrograman/Python/Project/google_image_scraper/Google-Image-Scraper/photos/food/test\"\n",
    "# saved_dir = \"D:/Pemrograman/Python/Project/google_image_scraper/Google-Image-Scraper/photos/new_dataset/xml_baru\"\n",
    "# os.chdir(saved_dir)\n",
    "\n",
    "# for xml_file in glob.glob(path + '/*.xml'):\n",
    "#     file_names = xml_file.split('\\\\')[1]\n",
    "#     tree = ET.parse(xml_file)\n",
    "#     root = tree.getroot()\n",
    "#     filename = root.find('filename').text\n",
    "#     for member in root.findall('object'):\n",
    "#         for obj in member.find('bndbox'):\n",
    "#             print(int(obj.text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/Pemrograman/Python/Project/google_image_scraper/Google-Image-Scraper/datasets/train\"\n",
    "saved_dir = \"D:/Pemrograman/Python/Project/google_image_scraper/Google-Image-Scraper/datasets/train/temp\"\n",
    "os.chdir(saved_dir)\n",
    "\n",
    "for xml_file in glob.glob(path + '/*.xml'):\n",
    "    file_names = xml_file.split('\\\\')[1]\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    filename = root.find('filename').text+'.JPEG'\n",
    "    root.find('filename').text = filename\n",
    "    root.insert(2,ET.fromstring(f'<path>{os.path.join(path,filename)}</path>'))\n",
    "    tree.write(file_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
